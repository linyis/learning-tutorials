# YouTube 影片摘要

- **影片連結**: https://youtu.be/7n9qbuzwS-U?si=SQCrxim1w_mCssDr
- **處理時間**: 2026-02-22 11:45
- **內容來源**: Faster-Whisper (large-v3-turbo) [zh]
- **分析模型**: ollama

## AI 分析結果 (中文摘要/翻譯)

1. **核心概念** - 影片主要介紹了如何利用OpenCloud來管理記憶、執行複雜任務並實現自動故障恢復。

2. **舉例說明**
   - 使用OpenCloud中的模型（如Anthropic的cloud ops 4.6和GPT5.2）進行不同類型的任务。
   - 將記憶文件拆分為不同的主題，以利於按需存取和管理這些記憶。
   - 利用Codex來擴展OpenCloud的深度搜索能力。
   - 自動重啟和修復故障中的OpenCloud Gateway，確保其持續運行。

3. **應用場景**
   - 使用不同類型的AI模型來執行複雜或特定任務，如編程、決策支持等。
   - 在記憶系統中組織信息以供快速存取和管理知識庫。
   - 通過深度學習引擎補充標準搜索引擎的功能，提供更高層次的信息查詢服務。
   - 自動檢測並修復OpenCloud運行中的問題，確保其穩定性和連續性。

4. **與其他概念的關聯**
   - 記憶管理和主題分類系統：影片展示了如何使用landsdb等工具來組織和管理複雜知識庫的方式，這在大數據分析和資料挖掘領域非常有用。
   - 自動化故障恢復機制：這種方法可以應用於任何需要高可用性的系統中，比如雲計算環境下的伺服器管理。

5. **簡短總結**
   影片介紹了如何利用OpenCloud平台進行複雜任務的執行、記憶管理以及自動化故障恢復。通過這些技術手段，不僅可以增強用戶體驗，還能提高工作效率和系統可靠性。

## 完整轉錄內容時間戳

- [00:00] 最近春节期间没有为大家制作与opencloud相关的视频
- [00:06] 但这期间我还是一直高强度使用opencloud
- [00:10] 并且总结了非常多的经验还有使用技巧
- [00:13] 而且我还对opencloud的记忆系统进行了重构
- [00:17] 将opencloud自带的markdown文件记忆系统
- [00:20] 重构为了landsdb的记忆系统
- [00:23] 在执行复杂任务的时候
- [00:24] 能够百分百命中我们记忆中所存储的这些采坑经验
- [00:29] 还有很多技术细节以及方法论
- [00:31] 由于最近我总结了opencloud的相关使用经验
- [00:35] 还有使用技巧还有方法论非常多
- [00:37] 所以本期视频我会分享几个比较有代表性的使用经验
- [00:41] 还有使用技巧
- [00:42] 如果本期视频的点赞量破千
- [00:44] 我会在下期视频为大家详细讲解
- [00:47] 如何重构opencloud的记忆系统
- [00:49] 将opencloud的记忆模块改为landsdb
- [00:52] 并且我会将我重构后的这个记忆模块的代码直接开源出来
- [00:56] 好下面我们就从简单到复杂
- [00:59] 来分享一下opencloud的使用经验
- [01:01] 还有使用技巧
- [01:02] 首先经过我这段时间高强度的使用
- [01:05] 最终我在opencloud中保留的模型其实并不多
- [01:08] 首先是Anthoropic的cloud ops 4.6这个模型
- [01:13] 虽然前两天Anthoropic发布了最新的cloud senate 4.6
- [01:17] 但经过我在opencloud中深度测试
- [01:20] 发现cloud senate 4.6
- [01:22] 它的agentic能力完全不如cloud ops 4.6
- [01:26] 所以我在opencloud中如果使用Anthoropic的模型的话
- [01:29] 我这里就会首选cloud ops 4.6
- [01:32] 对于一些不是非常复杂的任务的话
- [01:35] 我会选择openai codex中自带的gbt5.2模型
- [01:39] 对于gbt5.3 codex这款模型的话
- [01:42] 它并不适合在opencloud中执行复杂任务
- [01:46] 因为gbt5.3 codex这款模型
- [01:49] 它更适合用于编码场景
- [01:51] 它并不适合在opencloud中执行agentic等相关任务
- [01:56] 最关键的是codex中自带的gbt5.2模型
- [02:00] 它的额度要比Anthoropic的cloud ops 4.6额度要多很多
- [02:04] 当使用gbt5.2执行复杂任务的时候
- [02:07] 我们就可以直接用think命令
- [02:09] 来设置它的思考级别
- [02:11] 它默认是关闭的
- [02:12] 然后我们就可以根据我们的任务复杂程度
- [02:15] 来选择它的思考级别
- [02:17] 比如说我这里可以选择high
- [02:18] 这样的话就将gbt5.2它的思考级别调成了high
- [02:22] 然后我还保留了一个minimax的模型
- [02:24] 如果想给自己的opencloud加一个开源模型
- [02:28] 用于处理一些任务的话
- [02:29] 那么选择minimax m2.1这款模型是非常合适的
- [02:33] 它和opencloud非常搭配
- [02:35] 无论是响应速度还是推理能力
- [02:37] 在开源模型中它的效果都是非常不错的
- [02:40] 好下面继续为的也讲解opencloud与记忆相关的这些功能
- [02:44] 在之前的时候我将opencloud的这些记忆文件全部同步到了github进行备份防止丢失
- [02:51] 当记忆文件过多的时候
- [02:53] 我就让opencloud创建了一个topics文件夹
- [02:56] 在这个文件夹中
- [02:58] 我将记忆分为了不同的类别
- [03:00] 比如说关于opencloud多aging的相关的这些建议和技巧
- [03:05] 就单独存入这个文件中
- [03:07] 关于opencloud配置相关的这些记忆就单独存入这一个文件中
- [03:12] 关于浏览器自动化相关的这些经验就单独存入这一个文件中
- [03:17] 还有关于与doc配置相关的记忆
- [03:19] 还有与节点配置相关的这些记忆
- [03:22] 我全部都让opencloud将这些记忆做成了topics
- [03:25] 然后每一个话题就对应一个markdown文件
- [03:29] 这样的话opencloud就可以根据我们的场景按需加载不同场景下的这些记忆文件
- [03:35] 从而让记忆更明确
- [03:37] 想实现让opencloud按topics来拆分这些记忆非常简单
- [03:41] 我们只需要在opencloud中告诉opencloud按照主题来拆分memorymd这个文件
- [03:48] 然后opencloud它就能够理解按照主题来拆分memory
- [03:52] 将memory改为所以加核心规则
- [03:55] 当拆分完成之后memory这个文件的体积就会减小
- [03:59] 比如说我的这个memory文件在拆分之前
- [04:02] 它是一个15kb的单文件
- [04:04] 所有知识都混在一起
- [04:06] 当拆分之后在memory这个文件中
- [04:08] 它只存储缩影还有关键规则
- [04:11] 拆分之后可以看到它从15kb变成了2.3kb
- [04:14] 拆分后的这些文件就放入了memorytopics这个文件架中
- [04:19] 在这里就包含于opencloud配置相关的记忆
- [04:22] 多agent协作相关的记忆
- [04:24] 浏览器自动化
- [04:25] 外部服务加技能相关的记忆
- [04:27] 还有工作流规则相关的记忆
- [04:29] 相见的话就能够实现memorysearch
- [04:31] 能够按主题文件搜索从而实现精准命中
- [04:34] 而且每个主题都是独立膨胀
- [04:36] 不会相互干扰
- [04:37] 还能将新的知识追加到对应的主题文件中
- [04:41] 相见的话
- [04:42] 大家就可以将自己的memory文件
- [04:44] 按照主题
- [04:46] 然后opencloud进行拆分
- [04:48] 拆分成独立的文件
- [04:49] 好下面继续为大家讲解一下
- [04:51] 如何增强opencloud它的搜索功能
- [04:54] 因为opencloud它自带的搜索功能非常有限
- [04:57] 它支持的这个websearch功能
- [04:59] 我们需要设置brave的这个api
- [05:02] 然后它支持的这个工具
- [05:03] 只是起到url的内容抓取
- [05:06] 我们如果只使用opencloud自带的
- [05:09] 这两个搜索功能的话
- [05:10] 它的功能非常有限
- [05:12] 当我们进行非常复杂的搜索的时候
- [05:14] 这两个功能就很难满足我们的需求了
- [05:17] 为了给opencloud加入更强的深度搜索能力
- [05:21] 这里我写了一个skill
- [05:23] 看这个skill的名字
- [05:25] 大家应该就能猜出来
- [05:26] 我这里使用了codex的搜索功能
- [05:28] 因为codex它自带的这个搜索功能非常强大
- [05:32] 它的这个搜索功能属于deep research
- [05:34] 比如说我在codex中
- [05:36] 让它搜索cloudcode agent teams的使用场景
- [05:40] 然后在codex中
- [05:42] 它就进行了深度搜索
- [05:44] 在这里它就给出了搜索结果
- [05:46] 然后我就将codex的这个搜索功能
- [05:49] 做成了这个skill
- [05:51] 并且添加到了opencloud中
- [05:53] 在opencloud中
- [05:54] 我们只需要使用相关面领加codex
- [05:56] 就可以看到这个搜索功能
- [05:59] 在后面加上要搜索的内容
- [06:01] 比如说搜索cloudcode agent teams的使用场景
- [06:05] 当我们将搜索任务发送给它的时候
- [06:07] 然后这里它就会提示
- [06:09] 它已经启动深度搜索
- [06:11] 当搜索完成之后
- [06:12] 这里它就列出了搜索到的这些相关的内容
- [06:16] 甚至它给出了对应的链接
- [06:17] 然后这里还给出了详细的这些分析
- [06:20] 在这里它还给出了完整的检索报告
- [06:23] 像这样的话
- [06:24] 我们就将codex它强大的搜索能力
- [06:27] 对接到了opencloud中
- [06:29] 然后我们可以看一下这个搜索功能的决策数
- [06:32] 首先是用户提出需求
- [06:34] 比如说帮我查一下什么资料
- [06:37] 帮我搜索一下什么内容
- [06:38] 首先会判断用户是否输入了url
- [06:41] 如果输入了url就直接通过它的这个webfetch来抓取网易内容
- [06:46] 抓取为markdown格式
- [06:47] 如果没有输入url或者网址的内容
- [06:50] 然后用户搜索的内容只是一个非常简单的事实查询
- [06:54] 这样的话就会调用自带的这个brave进行搜索
- [06:58] 当用户输入的内容非常复杂
- [07:01] 并且是多元
- [07:02] 需要深度研究的时候
- [07:03] 那么就会调用codexcri进行多轮搜索
- [07:07] 然后我们就可以输入提示次测试一下
- [07:10] 调用codex深入研究一下
- [07:12] ai agent的最新进展
- [07:13] 然后我们直接发送
- [07:15] 然后这里他很快就给出了
- [07:17] 以用codex做完一轮
- [07:19] 最近三到六个月为主的深度调研报告
- [07:22] 这里是核心结论
- [07:23] 这里他给出了具体的这些来源
- [07:26] 然后在这里他又给出了第二轮的这些调研
- [07:29] 这样的话我们就实现了直接通过scale
- [07:33] 在opencloud中直接整合codex的深度搜索能力
- [07:37] 来弥补opencloud
- [07:38] 他自带的搜索工具搜索能力不足的情况
- [07:42] 好
- [07:42] 这个调用codex实现深度搜索功能的skill
- [07:46] 我也会放在笔记中
- [07:48] 好
- [07:48] 下面我们再看一下另一个非常重要的场景
- [07:52] opencloud的gateway重启防护机制
- [07:54] 因为我们在使用opencloud的时候
- [07:57] 他很可能会因为一些插件出现了bug
- [08:00] 导致opencloud它的gateway异常退出
- [08:04] 而且无法启动
- [08:05] 而且我在今天凌晨就遇到了我的gateway异常退出
- [08:09] 在这种情况下就会调用cloudcode来修复这些插件导致了gateway无法启动的情况
- [08:16] 当cloudcode修复完成之后
- [08:19] 这里就提示gateway已经被自动修复
- [08:21] 并且重启成功
- [08:23] 然后当早上我醒来
- [08:25] 我看到了这个日志提示的时候
- [08:27] 我就直接问他为什么会收到gateway启动失败的通知
- [08:31] 因为这段时间我并没有进行操作
- [08:33] 然后opencloud就对gateway进程崩溃的原因进行了分析
- [08:38] 这里他发现是钉钉插件
- [08:40] 在重联过程中抛了未捕获的异常
- [08:43] 最后导致整个进程都崩溃
- [08:45] 当gateway启动失败之后
- [08:47] 这里就会触发自动修复的这个服务
- [08:50] 下面我们看一下
- [08:51] 我是如何在opencloud中实现的gateway重启防护机制
- [08:55] 当gateway因为一些异常原因而崩溃而退出的时候
- [09:00] 就会触发systemd unfilient
- [09:02] 然后就会自动启动修复服务
- [09:05] 这个修复服务就是写的一个脚本
- [09:08] 然后这个脚本就会自动读取gateway的日志
- [09:10] 也就是这个脚本
- [09:12] 它会自动调用cloudcode
- [09:14] 把它获取到的日志信息等内容告诉cloudcode
- [09:18] 然后让cloudcode进行详细的分析
- [09:20] 包括opencloud json语法错误
- [09:22] 还有插件相关的配置错误
- [09:24] 还有端口冲突等内容
- [09:26] 所以这一步cloudcode就会读日志定位问题
- [09:30] 修改配置代码
- [09:31] 验证json语法
- [09:32] 当修复之后
- [09:33] 它就会重启gateway
- [09:35] 当重启8秒后
- [09:36] 它就会再次检查gateway是否还在运行
- [09:39] 如果还在运行
- [09:40] 就说明修复成功
- [09:41] 当8秒之后
- [09:42] 它检测到gateway的进程已经不存在
- [09:45] 那它就会尝试第二次修复
- [09:47] 也就是继续这个过程
- [09:49] 先读日志定位问题
- [09:51] 然后修改代码
- [09:52] 验证json语法
- [09:53] 再重启gateway
- [09:54] 再检测gateway是否崩溃
- [09:56] 如果修复两次还没有修复成功
- [09:59] 那么它就会通过聊天软件来通知用户
- [10:02] 让用户介入进行修复
- [10:04] 这个功能包含这几个相关的配置文件
- [10:07] 还有刚才我们所看到的这个脚本
- [10:10] 我会将这些配置内容
- [10:11] 还有相关的代码都放入笔记中
- [10:14] 然后大家只需要将这些代码发送给你的opencloud
- [10:17] 让opencloud自动为你设置就可以
- [10:19] 像这样的话我们就实现了opencloudgateway的自动修复
- [10:23] 哪怕在无人职守的状态
- [10:26] gateway因为插件的bug导致崩溃
- [10:28] 那么也可以由cloudcode自动为我们修复我们的gateway
- [10:33] 从而不需要我们手动去操作
- [10:35] 就可以完全实现gateway的恢复
- [10:37] 这样的话我们就不用担心
- [10:39] gateway因为异常退出
- [10:40] 而需要人工介入才能将它修复
- [10:43] 好 由于时间有限
- [10:44] 本期视频先为大家分享这些内容
- [10:47] 后续还会为大家讲解更多关于opencloud
- [10:50] 相关的使用经验还有使用技巧
- [10:52] 好 本期视频就做到这里
- [10:54] 欢迎大家点赞 关注和转发
- [10:57] 谢谢大家观看
- [10:58] 感谢观看
