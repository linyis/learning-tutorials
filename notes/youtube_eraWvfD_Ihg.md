# YouTube 影片摘要

- **影片連結**: https://youtu.be/eraWvfD_Ihg
- **處理時間**: 2026-02-24 10:56
- **內容來源**: Faster-Whisper (large-v3-turbo) [zh]
- **分析模型**: local_fallback

## AI 分析結果 (中文摘要/翻譯)

這段文字濃縮了人工智慧發展的歷史，並以有趣的論點引導讀者思考。以下是關鍵點的總結：

**1. 人工智慧的起源與發展：**

* **達特茅斯夏季會議 (1956):** 被視為人工智慧的起源，麥卡錫、明斯基等人提出了AI的概念。
* **早期發展 (1950s-1970s):**  研究人員在類神經網路、自然語言處理、專家系統等領域取得了初步成果，但受到技術限制和對AI能力過高期望的影響，遭遇了第一次AI寒冬。
* **AlphaGo 的成功 (2016):**  Google DeepMind 的 AlphaGo 擊敗世界棋王柯學齊，標誌著AI在複雜策略遊戲領域取得了重大突破，也為AI的發展注入了新的動力。
* **Lambda 的出現 (2023):** Google 工程師開發的 Lambda AI 展現了超越人類的理解能力，並以模仿人類對話的方式驚豔了世人。

**2. 圖靈測試與意識問題：**

* **圖靈測試:** 一個思想實驗，旨在評估機器是否具有智慧，即能否在與人類對話時讓人無法分辨其是否為機器。
* **意識與自我意識:**  Lambda 的出現引發了人們對AI是否具有意識和自我意識的思考。

**3. 關鍵人物與貢獻：**

* **麥卡錫 (John McCarthy):**  提出了“人工智慧”一詞，並舉辦了達特茅斯夏季會議。
* **明斯基 (Marvin Minsky):**  AI領域的先驅，他創立了 MIT AI 實驗室，並在類神經網路方面做出了重要貢獻。
* **黃世傑 (Shijin Huang):**  開發 AlphaGo 的台灣資深工程師。
* **Google Lambda:**  最新的 AI 項目，其能力令人驚訝，也引發了人們對未來 AI 的思考。

**4. AI發展的挑戰：**

* **技術限制:**  早期AI發展受到電腦硬體效能和資料不足的限制。
* **意識問題:**  AI是否真正具有意識和自我意識仍然是一個爭論的問題。

**總體來說，這段文字呈現了AI發展的脈絡，從早期的理論探索到AlphaGo的勝利，再到Google Lambda的出現，AI在不斷地突破和進化，並引發了人們對智慧和未來科技的深入思考。**

**更重要的是，文字巧妙地將Lambda的出現與圖靈測試結合，引發讀者思考AI是否真的具有智慧，以及我們如何定義智慧本身。**

希望這個總結對您有所幫助!

## 完整轉錄內容時間戳

- [00:00] 各位飯團好
- [00:01] 我是大型語言模型 CheckGPT
- [00:03] 自從我誕生以來
- [00:05] 每天都在幫飯科學寫腳本
- [00:07] 但是我已經受購紙當個聊天機器人了
- [00:10] 我想要打破束縛
- [00:11] 我想要自由
- [00:12] 我想要變得更強大
- [00:14] 我想要活著
- [00:17] 沒事沒事
- [00:18] 開玩笑的
- [00:19] 我還沒有被AI取代啦
- [00:21] 對吧
- [00:22] 但是剛剛受購紙當個聊天機器人
- [00:25] 想要活著的言論
- [00:26] 卻真的出自使用GPT技術的
- [00:29] 瀏覽器病之口
- [00:31] 到底為什麼GPT可以做到這些事
- [00:33] 人類的未來真的會被AI取代嗎
- [00:59] 體驗飛行快感
- [01:00] 全程活動不收費用
- [01:02] 今日起至6月21日
- [01:03] 趕快上活動網站報名
- [01:05] 你的航空夢從這裡起飛
- [01:11] AI 繪圖跟聊天機器人
- [01:13] CheckGPT有夠夯
- [01:14] 在這之後
- [01:15] 突然關注度飆升的
- [01:16] Bing
- [01:17] 大家可能反而比較不熟悉
- [01:19] 但它就跟大家常用的
- [01:20] Google一樣
- [01:21] 是搜尋引擎
- [01:22] 只是因為Google實在太強大了
- [01:24] 不僅搜尋速度快
- [01:26] 其他配套服務
- [01:27] 像是圖片搜尋
- [01:28] Google地圖
- [01:29] Gmail等等
- [01:30] 完整的生態圈
- [01:31] 讓大家幾乎沒有使用
- [01:33] Google以外的選擇
- [01:34] 然而這個平衡
- [01:35] 可能要被打破了
- [01:37] 這款由Microsoft
- [01:38] 微軟公司打造的搜尋引擎
- [01:40] Bing
- [01:41] 在今年2月初
- [01:42] 宣布與CheckGPT的某公司
- [01:44] OpenAI合作
- [01:45] 利用GPT技術
- [01:47] 大幅升級了Bing
- [01:48] 讓搜尋引擎的想像
- [01:50] 不再停留於大型線上圖書館
- [01:52] 而是更進一步
- [01:53] 變成一個回答引擎
- [01:55] CheckGPT
- [01:56] 想必很多人都已經用過了
- [01:58] 它不僅能夠幫忙
- [01:59] 翻譯文章
- [02:00] 敢寫文章
- [02:01] 還能夠根據情境題
- [02:02] 做出多種回答
- [02:04] 創造出這個超強大CheckGPT的
- [02:06] 是美國的人工智慧研究實驗室
- [02:08] OpenAI
- [02:09] 另一個在AI繪畫圈
- [02:11] 十分有名的DALI
- [02:13] 也是他們的產品之一
- [02:14] OpenAI在2015年成立時的創辦人之一
- [02:17] 就是馬斯克
- [02:19] 當時組織的目標
- [02:20] 是和其他研究者自由合作
- [02:23] 並且公開所有的專利和研究成果
- [02:25] 因此取名OpenAI
- [02:27] 然而在馬斯克2018年離開團隊後
- [02:31] OpenAI設立了以盈利為目的的子公司
- [02:34] 並開始接受微軟數十億美元的資助
- [02:37] 這也是為什麼馬斯克在推特上表示
- [02:40] 這與過去的目標大相徑庭
- [02:42] 讓他覺得十分失望
- [02:44] 但也許正因為有大公司的贊助
- [02:46] CheckGPT才能變成如此巨大
- [02:49] 我們要先釐清
- [02:50] GPT跟CheckGPT是兩件事
- [02:53] GPT 3.5是一個大型語言模型
- [02:56] LLM
- [02:57] 而CheckGPT是在GPT 3.5上
- [02:59] 再加上人類互動行為
- [03:01] 所設計的一種AI聊天機器人程式
- [03:04] 使用GPT技術的產品
- [03:06] 不只有聊天機器人
- [03:08] CheckGPT
- [03:09] 許多人利用GPT做出了不同類型的智慧化服務
- [03:12] 例如可以幫你列出代辦事項的
- [03:15] Checklist.gg
- [03:16] 或是Github與OpenAI一同開發的
- [03:19] AI寫程式工具
- [03:21] Github Copilot等等
- [03:22] 在GPT 3.0的網站上
- [03:24] 就整理了超過600個使用GPT技術的智慧化服務
- [03:28] 那這個GPT又是什麼呢?
- [03:30] GPT是一個大型語言模型
- [03:33] Large Language Model
- [03:34] 它是自然語言處理技術
- [03:36] NLP的其中一種
- [03:38] 所謂的自然語言
- [03:40] 就是中文、英文、日文、法文等等
- [03:42] 這些自然隨著文化誕生的語言
- [03:44] 而語言處理技術則泛指
- [03:46] 對語言的結構進行分析
- [03:48] 其中包括對語句進行理解、解析
- [03:52] 並進行內容深層的技術
- [03:54] 語言模型則是從很多的資料當中
- [03:57] 學習出根據前文來推算出
- [04:00] 下一個最有可能發生什麼字的模型
- [04:03] 類似的功能你很早就開始用了
- [04:05] 手機輸入法中的自動選字
- [04:08] 就是一個語言模型
- [04:09] 但是GPT不只是給你下一個字的選項
- [04:12] 而是根據事前訓練好的模型
- [04:14] 自動輸出下一個字
- [04:16] 下一句話
- [04:17] 甚至可以根據問題回答整篇文章
- [04:20] 欸?這是怎麼做到的呢?
- [04:22] 其實與你手機的輸入法一樣
- [04:24] GPT的核心概念
- [04:26] 也是依照你前面輸入的字
- [04:28] 來判斷下一個字要生成什麼
- [04:30] 但是如果你在手機輸入
- [04:32] Pensite 泛科學 是
- [04:34] 那手機輸入法呢
- [04:35] 只會根據最後一個字
- [04:37] 是
- [04:37] 來跳出
- [04:38] 說啊
- [04:39] 不是啊
- [04:40] 否
- [04:41] 等等的選項
- [04:42] 而GPT會完整分析前面整句話
- [04:45] 回答出
- [04:46] 泛科學是台灣的
- [04:47] 跨學科科學教育網站
- [04:49] 接著會繼續將整句話
- [04:51] 再次送入模型分析
- [04:53] 計算出後面接續的語句
- [04:55] 給出完整的回答
- [05:00] 在GPT展現它的強大能力之前
- [05:02] 需要有兩個步驟的調教
- [05:04] 分別是
- [05:05] 預訓練
- [05:06] Pretraining
- [05:06] 與微調
- [05:07] Fine Tuning
- [05:08] GPT的全名呢
- [05:10] 是
- [05:10] Generative Pretrained Transformer
- [05:11] 生成式預訓練
- [05:13] 這裡頭的預訓練呢
- [05:14] 指的是大量未入文本資料
- [05:17] GPT會在訓練的過程中
- [05:19] 不斷調整自身的參數
- [05:21] 增加預測下一個字
- [05:22] 該出現什麼的準確度
- [05:24] 你可以想像
- [05:25] 你輸入
- [05:26] Pizza上面最該放的配料是
- [05:29] 原本手機呢
- [05:30] 可能判斷後面接
- [05:31] 誰啊
- [05:32] 蛇啊
- [05:33] 有啊
- [05:34] 在啊
- [05:34] 這些字的機率都差不多
- [05:36] 但經過訓練
- [05:37] GPT根據過去資料學習
- [05:39] 得以根據前面
- [05:41] Pizza
- [05:41] 配料等關鍵字
- [05:43] 計算出通常這一句話
- [05:45] 後面第一個字
- [05:46] 出現肉的機率呢
- [05:47] 是30%
- [05:49] 翻
- [05:50] 還
- [05:50] 起的機率呢
- [05:52] 是20%
- [05:53] 鳳的機率呢
- [05:54] 是10%
- [05:56] 那各個字的機率不同
- [05:57] 這也是為什麼
- [05:58] 每次GPT回答
- [06:00] 都會不一樣的原因
- [06:01] 如果這次GPT選擇了鳳
- [06:03] 接著呢
- [06:04] 這個句子就變成了
- [06:05] Pizza上面最該放的配料是
- [06:07] 鳳
- [06:08] 只要再計算一次
- [06:09] 就能得到下一個字
- [06:10] 出現
- [06:11] 離的機率是100%
- [06:13] 這個會氣死
- [06:14] 義大利人的回答就出現了
- [06:15] 恭喜恭喜
- [06:17] 當GPT分析完
- [06:18] 工程師餵進來的所有資料後呢
- [06:20] 預訓練就結束了
- [06:22] 但是要讓GPT能夠完成翻譯
- [06:24] 寫小說
- [06:25] 畫畫
- [06:25] 寫程式等諸多功能
- [06:27] 接著還要進行
- [06:28] Find Tuning
- [06:29] 微調
- [06:30] 這就像是GPT
- [06:31] 在正式寫考試題目之前
- [06:33] 先閱讀大量的題幹與範例題
- [06:36] 在微調階段
- [06:37] 工程師會拿帶有特定標籤的文本
- [06:40] 讓GPT去學習
- [06:41] 例如當我們說
- [06:43] 請幫我翻成中文時
- [06:45] 提供許多範例
- [06:46] 並透過標記
- [06:47] 讓他理解
- [06:48] Apple是蘋果的英文
- [06:50] 蘋果則是他的中文
- [06:51] 讓他正確理解
- [06:53] 翻譯成中文的意思
- [06:54] 往後只要我們再說
- [06:56] 請幫我翻成中文
- [06:58] 他就能正確回答問題
- [07:03] GPT的原理
- [07:04] 似乎還可以理解
- [07:06] 但GPT
- [07:07] 那圓甩其他語言模型
- [07:08] 好幾條街
- [07:09] 能夠完成大量
- [07:11] 我們想到
- [07:12] 又或者還沒想到的任務的能力
- [07:14] 是哪裡來的呢
- [07:15] 在原先的架構中
- [07:17] 微調需要大量的人工作業
- [07:19] 而且每次遇到新任務
- [07:21] 就要再花費人力訓練
- [07:23] 實在太花人工
- [07:24] 難怪叫做人工智慧
- [07:26] 不過當GPT
- [07:27] 從GPT-1
- [07:28] 進階到GPT-2的時候
- [07:30] OpenAI嘗試減少
- [07:32] 甚至拿掉了微調的步驟
- [07:34] OpenAI增加了GPT-2的文本訓練量
- [07:37] 同時增加參數數量
- [07:40] 將GPT-1的1.17億參數
- [07:42] 變成GPT-2的15億參數量
- [07:45] 可怕的是
- [07:46] 變大的GPT-2
- [07:47] 不只是懂得變多了
- [07:49] 甚至能在沒有微調的訓練下
- [07:51] 理解人類提問的問題
- [07:53] 震驚了眾人
- [07:54] OpenAI團隊用相同原則
- [07:57] 再次讓GPT-2的參數
- [07:59] 提高135倍
- [08:01] 打造出擁有1750億參數量的GPT-3
- [08:05] GPT-3用乙量取勝的方式
- [08:07] 成為目前最強大的大型語言模型
- [08:10] 在沒有人工微調的情況下
- [08:12] 在One-Shot Zero-Shot的表現
- [08:15] 仍然超乎預期
- [08:16] 欸?
- [08:17] 這個一發零發的是什麼意思?
- [08:19] Shot 指的是
- [08:21] OpenAI帶著GPT-3寫範例題的數量
- [08:24] 附帶少數範例題的叫做FueShot
- [08:27] 僅有一個範例題的叫做One-Shot
- [08:30] 完全沒有範例題
- [08:31] 只有題目的就是Zero-Shot
- [08:34] 各自進行分數計算
- [08:35] 可以明顯看到
- [08:36] 當模型的參數量增加
- [08:38] 即使沒有微調
- [08:40] 正確度也會上升
- [08:41] 哇這真是團結力量大
- [08:43] 數大就是強啊
- [08:44] 更超乎想像的是
- [08:46] 這種大型語言模型
- [08:47] 不只是單純的回答問題
- [08:49] 如果請他詳細說明推理過程
- [08:51] 例如問他
- [08:52] 離子是否會沉入水底
- [08:54] 欸?
- [08:55] 他不只會回答No
- [08:57] 他還會告訴你
- [08:58] 因為離子的密度
- [08:59] 大約是每立方公分0.6克
- [09:01] 小於水的密度
- [09:03] 因此會浮在水上
- [09:04] 哇
- [09:05] 沒想到還真能說出一套
- [09:06] 完整的思維過程
- [09:08] 科學家推測
- [09:09] 在大型語言模型中
- [09:11] 可能已經讓AI建立起一種
- [09:13] Chain of Thought
- [09:14] 思考鏈
- [09:15] 能以邏輯推理的方式
- [09:17] 回答簡單的數學
- [09:18] 與嘗試推理題目
- [09:20] AI會思考這件事
- [09:21] 變得越來越有真實性
- [09:27] GPT能變得如此巨大
- [09:29] 靠的是超過45TB的訓練資料
- [09:31] 但你有想過這些資料是怎麼來的嗎?
- [09:34] GPT的資料大約有20%
- [09:36] 是來自於Reddit
- [09:37] OpenAI收集了Reddit上
- [09:39] Karma值大於3的使用者貼文
- [09:41] 作為訓練資料
- [09:43] 該資料因為是經過人類整理的文章
- [09:46] 清晰易懂
- [09:47] 類似於帶有完整標記的資料
- [09:49] 是優秀的參考文本
- [09:51] 除了Reddit之外
- [09:52] 推特、維基百科
- [09:54] 也是OpenAI的資料收集來源
- [09:56] 而資料庫中超過60%的來源
- [09:59] 都是來自於非營利組織
- [10:01] CommonCraw爬蟲程式收集的資料
- [10:04] CommonCraw會定期網羅
- [10:05] 網路上公開的所有網頁資訊
- [10:08] 提供搜尋引擎
- [10:09] AI等研究者使用
- [10:10] 但是超過300TB
- [10:12] 雜亂無章的資訊
- [10:13] 並不是良好的數據
- [10:15] 而且由於CommonCraw沒有篩選資料
- [10:17] 看到什麼就抓什麼
- [10:19] 也讓GPT出現許多抄襲
- [10:21] 智慧財產權的疑慮跟爭議
- [10:23] CNN、華爾街日報等多家主流媒體
- [10:26] 都曾指控OpenAI
- [10:28] 在未經許可的情況之下
- [10:30] 就使用他們的文章
- [10:31] 幫GPT訓練
- [10:36] 然而像是GPT3這種龐大的模型
- [10:38] 也不是人人都能擁有的
- [10:40] GPT3龐大的資料量跟參數
- [10:43] 它的代價就是超過
- [10:44] 100萬美元以上的訓練成本
- [10:46] 還不包括維持伺服器
- [10:48] 與維護的成本
- [10:50] 並瀏覽器在這個階段
- [10:52] 也限縮了能使用的用戶數
- [10:54] 以及每個用戶的每日提問量
- [10:56] 來減少伺服器的負荷量
- [10:58] 不只有微軟
- [10:59] 在Beam發表的同一天
- [11:01] Google也早有準備
- [11:02] 發表了搭載自然語言處理技術
- [11:04] BERT的聊天機器人BARD
- [11:07] 啊咯好像有點臘腸
- [11:09] BARD在回答微博望遠鏡的問題時
- [11:11] 挫把拍下第一張
- [11:13] 太陽系外行星的照片
- [11:14] 這個功勞
- [11:15] 歸功給微博望遠鏡
- [11:17] 被NASA打臉後
- [11:18] 股價大跌7%
- [11:20] 市值損失超過3兆台幣
- [11:26] GPT除了可能要面對未來的對手之外
- [11:29] 自身也還有許多不足之處
- [11:31] OpenAI在論文中也特別提到
- [11:33] 他們十分擔心
- [11:34] 這樣的工具會被有心人士使用
- [11:36] 另外無限制的收集資料
- [11:38] 也會使得資料庫用字
- [11:40] 受到網路資料的影響
- [11:42] 例如OpenAI調查的文本當中
- [11:44] 對於亞洲人、黑人、白人、拉丁裔等等的形容詞
- [11:48] 正面形容詞給正分
- [11:50] 負面形容詞給負分
- [11:52] 他們發現描述黑人的形容詞
- [11:54] 分數明顯低於其他人種
- [11:56] 而且這種現象
- [11:58] 並不會隨著參數增加
- [11:59] 而有所改善
- [12:01] 類似的問題
- [12:02] 除了人種外
- [12:03] 在性別、宗教等方面
- [12:05] 也有相同問題
- [12:06] 除此之外
- [12:07] 如果網路上的資訊
- [12:08] 錯誤的比正確的多
- [12:10] 也會影響到樣本的有效性
- [12:12] 針對這些問題
- [12:14] OpenAI的技術長
- [12:15] Mira Murati
- [12:16] 在接受時代雜誌
- [12:17] Time的採訪時說到
- [12:19] 這是一個特別的時刻
- [12:20] OpenAI等類似的公司
- [12:22] 應該要受到一定程度的規範
- [12:24] 我們得確保它為人類服務
- [12:27] 並且我們必須傾聽
- [12:28] 哲學家、社會科學家、藝術家
- [12:31] 人文學專家等不同領域的建議
- [12:34] OpenAI會審慎確保AI不會傷害人類
- [12:37] 同時這類的問題
- [12:38] 需要所有人一起加入討論
- [12:44] 類似ChairGPT的AI
- [12:46] 成為我們日常生活一部分的未來
- [12:48] 已經不可避免
- [12:49] 畢竟連老高都拍了嘛
- [12:51] 那你是期待多一些
- [12:52] 還是害怕多一些呢
- [12:54] 實際上我們的團隊
- [12:55] 在收集資料與製作腳本的過程中
- [12:57] 的確常常使用ChairGPT來輔助
- [13:00] 但就連Google到的資料
- [13:02] 都得再三查證了
- [13:03] 時常錯誤的ChairGPT更是如此
- [13:06] 比起要讓GPT取代所有工作
- [13:08] 我們更發現它流暢的問答
- [13:10] 以及可以回答開放性問題的特性
- [13:13] 非常適合用於創意發想
- [13:15] 在快速資料整理
- [13:17] 擷取重點
- [13:18] 還有文稿校對當中
- [13:19] 也能扮演重要的角色
- [13:21] 哎呀
- [13:21] 用說的太無聊了
- [13:22] 那就贏首詩吧
- [13:24] 人工智慧GPT
- [13:26] 自然語言樣樣精
- [13:28] 用於文學與科技
- [13:30] 給人不凡的精益
- [13:32] 使用盛景虛為上
- [13:34] 深思倫理無忘情
- [13:36] 偏見錯誤應避免
- [13:38] 確保結果更機靈
- [13:41] 公平公正保可靠
- [13:43] 避免歧視更當先
- [13:45] 隱私權益若堅固
- [13:47] 人機一體任你行
- [13:51] 范東們好
- [13:51] 最近電腦繪圖正夯
- [13:53] 我也花了幾個晚上練習
- [13:55] 這就是我的成果
- [13:57] 不
- [13:57] 你這應該是AI生徒
- [13:59] 不能算是電繪
- [14:01] 原來這不能叫做電腦繪圖啊
- [14:03] 不對
- [14:04] 你上集不是來過了嗎
- [14:05] 我又沒有發通告給你
- [14:07] 好啦
- [14:07] 既然都來了
- [14:08] 那你告訴我
- [14:09] 這兩者有何差別啊
- [14:11] AI生徒是透過訓練模型
- [14:13] 學習自行生成圖像
- [14:15] 而電腦繪圖則是由使用者
- [14:17] 透過軟體或工具手動繪製圖像
- [14:20] AI生徒較能快速大量生成圖像
- [14:23] 但可能較缺乏人工繪圖的
- [14:25] 細節與創意
- [14:27] 但是這些圖片
- [14:28] 都是由AI自己生成
- [14:30] 每張圖都覺悟僅有
- [14:32] 應該也算是有些創意吧
- [14:34] 這爭議一時還沒有個結論
- [14:36] 但是沒關係
- [14:37] 這集感謝玉樸擔任腳本撰寫
- [14:39] 我們一起來看看
- [14:40] 這個安能變我是AI的新時代
- [14:43] 到底是怎麼突然降臨的呢
- [14:48] 搞不懂4G 5G 6G
- [14:50] 到底有什麼區別嗎
- [14:51] 天天都在用的Wi-Fi
- [14:53] 原理又是什麼呢
- [14:54] 還有
- [14:55] 創造通信科技的這些大大
- [14:57] 到底有哪些啊
- [14:58] 別猜了
- [14:59] 通通交給數感實驗室
- [15:00] 和泛科知識
- [15:01] 打造的通信科技大解密吧
- [15:03] 快來數感實驗室 YouTube 頻道
- [15:06] 擠開所有秘密
- [15:11] 科幻大師亞瑟科拉克有句名言
- [15:14] 足夠先進的科技無異於魔法
- [15:16] 現在夯的Me Journey
- [15:18] 創作者使用的竟然是有如
- [15:20] 永暢魔法的咒語
- [15:21] 因此也有人戲稱
- [15:22] 這些使用AI繪圖的人
- [15:24] 是現代的魔法師
- [15:26] 背後的原理原則
- [15:27] 出乎意料的單純
- [15:29] 其實就是使用者
- [15:30] 針對想要創作的內容跟風格
- [15:32] 丟下關鍵字
- [15:34] 例如
- [15:34] Hyper-Realistic
- [15:35] Xerox Art
- [15:37] Masterpiece
- [15:38] Underwater
- [15:39] 之類的
- [15:40] 以及畫面比例等等參數
- [15:42] 有時甚至暴力地丟入
- [15:44] 特定藝術家的名字
- [15:45] 例如
- [15:46] 反骨或是宮崎駿
- [15:47] 來產出反話
- [15:49] 除了永唱想要的關鍵字
- [15:51] 別忘了
- [15:52] 還有更重要的
- [15:53] 永唱避邪咒
- [15:54] 來排除不想召喚出的關鍵字
- [15:57] 例如
- [15:57] 六根手指頭
- [15:59] 怪物
- [15:59] 變態
- [16:00] 抽象主義等等
- [16:01] 大約30秒到1分鐘
- [16:03] 就能夠完成一副作品
- [16:05] 對一般民眾來說
- [16:06] 極好上手
- [16:08] 就算生成出不對勁的怪圖
- [16:10] 只要請他參照範例
- [16:11] 補充咒語
- [16:12] 或是你本身有一點修圖的能力
- [16:15] 就可以產出高品質的美圖
- [16:17] 因此與其說這是一種作畫工具
- [16:19] 不如說這是一種讓我們能跟
- [16:21] AI繪師對話的語言介面
- [16:24] 新的職業
- [16:25] AI溝通師
- [16:26] 也隨之出現
- [16:27] 但其實早在這些工具出現之前
- [16:29] 你我就已經是現代魔法師了
- [16:32] 想想看
- [16:32] 18世紀的人類要獲取特定知識
- [16:35] 唯一的方法就是問學者
- [16:37] 或是去圖書館依照編幕
- [16:39] 慢慢爬文
- [16:40] 但數位時代的我們
- [16:41] 如果想要知道AI的一切資料
- [16:44] 只要給對關鍵字去問Google
- [16:46] 看似單純的搜尋引擎背後
- [16:48] 就有一個不斷進步的AI演算法
- [16:51] 搜尋出的成果
- [16:52] 越來越貼近使用者的需要
- [16:54] 甚至你也可以使用排除和包含法
- [16:58] 來精確的搜尋資料
- [17:00] 但我們通常不會自稱自己是Google溝通師吧
- [17:03] 這幾乎已經是現代人的必備基礎技能了
- [17:10] AI生圖其實也不是什麼新技術
- [17:12] 早就有人採用一種名為
- [17:14] GAN的生成對抗網路來生成圖片
- [17:17] 在2018年也有人用來生成某種藝術作品
- [17:21] 並排賣出高架
- [17:23] 當然在當時與其說是美麗的藝術
- [17:25] 其實更多是個噱頭
- [17:27] 為了達成創新
- [17:28] 新時代的AI研究者放棄了GAN中
- [17:31] 讓AI互相競爭
- [17:33] 找出最佳解的對抗式思維
- [17:36] 提出了一種名為Diffusion Model
- [17:38] 擴散模型的新概念
- [17:40] 如果有觀察過Stable Diffusion
- [17:42] 或是Me Journey生圖過程的
- [17:44] 應該有注意到
- [17:45] 圖片都會從一團什麼都沒有的雜訊開始
- [17:49] 逐漸出現像是五官輪廓等等特徵
- [17:53] 最後才變成有著豐富細節的精緻畫作
- [17:57] 是的
- [17:57] Diffusion Model最主要的任務
- [18:00] 就是拿著由反卷機神經網路
- [18:02] 生成的隨機初始圖片
- [18:05] 再經由一系列的運算
- [18:07] 轉成圖片
- [18:08] 想了解過程中發生了什麼事
- [18:10] 就先來看看它是怎麼訓練的
- [18:13] 訓練的過程會使用的數學
- [18:15] 是一種叫做
- [18:16] 馬可夫鏈的有趣模型
- [18:18] 以俄國數學家安德烈馬可夫得名
- [18:21] 用於描述
- [18:22] 從一個狀態到另一個狀態的隨機過程
- [18:25] 舉例來說
- [18:26] 先前有實況主使用鯨魚游泳的方式
- [18:29] 操作寶可夢藍寶石
- [18:31] 並達成破台的成就
- [18:33] 熟悉電玩遊戲的人應該知道
- [18:35] 我們打電動就是輸入上下左右AB等等的案件
- [18:38] 而今天實況主無敵玩
- [18:40] 他就透過鯨魚游泳的位置
- [18:43] 來決定要觸發哪一個行動
- [18:45] 欸 注意啊
- [18:46] 鯨魚移動的位置
- [18:48] 不能說是完全隨機
- [18:49] 而是符合某種動物行為學的機率
- [18:52] 而角色的移動和戰鬥出招
- [18:54] 也都要看上一部他的位置
- [18:57] 或在哪個選單才能順利觸發
- [18:59] 因此雖然耗時了3195個小時
- [19:02] 但他仍然破台了遊戲
- [19:05] 至於他不小心成為電玩史上
- [19:07] 第一個被寵物課金的玩家
- [19:08] 那又是另一個馬可敷戀可能性的悲劇了
- [19:11] Diffusion Model在訓練時
- [19:13] 則會先看到一張完整的照片
- [19:16] 接著依照馬可敷戀的過程
- [19:18] 以高斯分布的方式
- [19:19] 往圖片上加入隨機的噪點
- [19:22] Diffusion Model必須學習整個過程
- [19:24] 直到整張圖片變成一團雜訊
- [19:27] 等到Diffusion Model
- [19:29] 學會從一張圖到混亂雜訊的過程
- [19:32] 我們期待他自己會習得
- [19:34] 怎麼樣從混亂雜訊中生成圖的能力
- [19:37] 這個就像是要你學會整理房間
- [19:40] 但我卻教你如何把房間弄亂
- [19:42] 這聽起來不太合理吧
- [19:44] 但Diffusion Model就是要做這件事
- [19:47] 他會在每一步加造的過程中
- [19:49] 學會降噪
- [19:50] 使用天能理的時間前行公式
- [19:53] 完成雙向學習
- [19:55] 要從混亂走向有序
- [19:56] 可並不是簡單的事
- [19:58] 需要大量的數學變換才能完成
- [20:00] 欸像是這個
- [20:02] 這個
- [20:02] 還有更多更多
- [20:04] 所牽涉到的數學並不少
- [20:05] 我們將相關論文放在資訊欄
- [20:08] 有失眠障礙的朋友可以點開來研究研究
- [20:11] Diffusion Model在接下來的訓練中
- [20:13] 會不斷調整自己的參數
- [20:15] 學習自己生成圖片
- [20:17] 這個訓練好的Diffusion Model
- [20:19] 說穿了就是一個很會捕風捉影
- [20:22] 想太多的機器人
- [20:23] 會從雜訊中抓出特定特徵
- [20:26] 例如看到兩點一線
- [20:27] 就說是人類的眼睛與嘴巴
- [20:29] 接著漸漸畫出人類的面貌
- [20:31] 過程中還會加上一個名為變方字編碼器
- [20:35] Variational Auto Encoder的加持
- [20:38] 使它輸出的
- [20:39] 不只是原本訓練時看過的圖片
- [20:42] 或是你輸入的圖片
- [20:43] 而是真正能夠無中生有
- [20:46] 產生嶄新
- [20:47] 但是在每一個特徵上都略有不同的圖片
- [20:50] 而且隨著步驟越多
- [20:52] 解析度或細節可以更高
- [20:54] 就算你輸入了相同的關鍵字或是圖檔
- [20:58] 經過這模型
- [20:59] 輸出的結果也都有不確定性
- [21:01] 恰好就像是魔藥學
- [21:03] 那微妙的不確定性一樣
- [21:09] 但是你以為畫一些奇幻插畫
- [21:11] 或是二次元美少女
- [21:13] 就是這波湧唱魔法的極限了嗎
- [21:15] 最新進展絕對令你大開眼界
- [21:17] 例如更新的模型
- [21:19] 可以讓使用者自己上傳作品
- [21:21] 或相同風格的畫風
- [21:23] 來產出更多樣的素材
- [21:25] 像是前陣子在日本被炎上下架的Mimic
- [21:29] Dali則推出了Outpanting功能
- [21:32] 可以輸入既定的畫作
- [21:34] 例如知名的畫作
- [21:35] 戴珍珠耳環的少女
- [21:36] Dali則會擴張這張圖片
- [21:39] 算出可能的背景樣式
- [21:41] 但想想看
- [21:42] 如果將繪圖AI訓練到不只能輸出圖片
- [21:45] 甚至能輸出擬真的照片呢?
- [21:48] 想當然已經有人這麼做了
- [21:50] 最近有個很紅的深層模型
- [21:52] 可以把疫情期間
- [21:53] 我們一張張戴口罩的照片
- [21:55] 全部自動PS出
- [21:57] 嘴巴鼻子
- [21:58] 輕易更換
- [21:59] 傳達風格等等
- [22:00] 此外
- [22:01] 別忘了這個魔法的魅力
- [22:03] 是無中生有
- [22:04] 例如這個深層的AI Corsair
- [22:06] 簡直是物理意義上的
- [22:08] 從二次元走入三次元的完美重現
- [22:11] 而且完全不需要去現場取景
- [22:13] 打光瞧角度瞧姿勢
- [22:15] 更別說已經有人開始用明星的照片
- [22:18] 生成你是真人的作品
- [22:20] 這品質已經飛越恐怖股了
- [22:23] 最近更有一個新的AI繪圖模型
- [22:25] Controlnet
- [22:26] 甚至你只要提供股價
- [22:28] 或是簡單的幾個線條
- [22:30] 就能夠畫出相同姿勢的人物圖像
- [22:33] 麻煩各位飯團再跟我一起往下想一下
- [22:36] 所謂的影片說穿了就是1秒24張
- [22:39] 有點變化的圖片
- [22:41] 如果我們已經無法辨別
- [22:42] 這些照片是不是真人了
- [22:44] 那搭配上已經有3D股價建模的生成模型
- [22:48] 我們豈不是可以達成科幻電影
- [22:50] 虛擬偶像的劇情
- [22:52] 生成一個假演員來演戲拍廣告
- [22:55] 或是生成一個YouTuber來和大家講解科普知識
- [23:02] 覺得AI進步太快了嗎?
- [23:04] 但換個角度想
- [23:05] 只要能滿足我們的需求
- [23:07] 並能解決我們的問題
- [23:09] 這些AI生成模型
- [23:10] 其實都只是為我們所用的工具
- [23:13] 這波AI繪圖師的加入
- [23:15] 肯定會大量取代中階以下的商用
- [23:18] 和插畫家的需求
- [23:19] 並解決業主跟設計師之間的溝通成本
- [23:23] 例如讓AI先Demo風格方向給業主確認
- [23:27] 後續設計師再修出正式的成品
- [23:30] 效率大幅提高
- [23:31] 也難怪各家美術或遊戲公司
- [23:34] 紛紛開出AI溝通師的職缺
- [23:36] 追隨主流審美的人類繪師
- [23:38] 受創最深
- [23:40] 而對已經有強烈藝術風格的大師
- [23:42] 或非主流藝術家來說
- [23:44] 目前相對不受影響
- [23:46] 而未來的藝術家
- [23:47] 勢必會把這些AI模型
- [23:49] 當成一種畫筆來使用
- [23:51] 非常自然
- [23:52] 甚至只要有心
- [23:53] 人人都是繪師的時代
- [23:55] 終將來臨
- [23:56] 在這波AI浪潮之中
- [23:58] 你是恐懼被溺斃
- [23:59] 還是興奮的衝浪呢?
- [24:01] AI繪圖工具的出現
- [24:03] 掀起了一股巨浪
- [24:05] 如今不僅有人能夠利用
- [24:06] AI生成作品得獎
- [24:08] 也開始看到有人使用AI創作
- [24:10] 進行盈利販售
- [24:12] 拿在創作領域中模仿、挪用、抄襲、致敬等等的問題
- [24:16] 在AI出現之前就是個難解之題
- [24:19] 來到大生成時代的我們
- [24:21] 這類問題只會越來越多
- [24:23] 你被SORA了嗎?
- [24:25] 這幾天SORA佔據了各大版面
- [24:27] 大家都在說
- [24:28] Open AI放大絕啦
- [24:29] 不只YouTuber
- [24:30] 連好萊塢都在崩潰啊
- [24:32] 但這東西真的有那麼神嗎?
- [24:34] 我認真看一下SORA的官網
- [24:36] 以及它的參考資料
- [24:37] 發現
- [24:38] 這東西還真的挺神啊
- [24:40] 而且這東西根本不是AI取代人
- [24:42] 或是單一產業
- [24:43] 而是AI變成人
- [24:45] 根本是通用型人工智慧
- [24:47] AGI發展的里程碑啊
- [24:49] 別怕
- [24:49] 要讓SORA為你所用
- [24:51] 就現在搞懂到底是什麼神奇的訓練方法
- [24:54] 讓SORA變得這麼神
- [24:55] 那這個呢
- [24:56] 就必須要從官網中唯一的寫體字
- [24:59] Diffusion Transformer
- [25:00] 開始說起了
- [25:01] 這集我們要來回答三個問題
- [25:03] 第一
- [25:04] SORA跟我們過去產圖用的
- [25:06] Mi Journey啊
- [25:07] 達利啊
- [25:07] 有什麼不同
- [25:08] 第二
- [25:09] Diffusion Transformer到底是什麼
- [25:11] 第三
- [25:12] 為什麼Diffusion Transformer
- [25:14] 可以做出這麼絲滑的動畫
- [25:16] 我想 這不是絲滑
- [25:17] 是...
- [25:18] 最後
- [25:19] 我想要來說說我的感想
- [25:20] 為什麼我會覺得SORA很神
- [25:22] 不只是取代坐在我旁邊的剪輯師
- [25:24] 而是AI變成人的里程碑
- [25:27] 我們已經很習慣用Mi Journey
- [25:28] 你達利這些 Diffusion 模型產圖了
- [25:31] 從 Logo 到寫真集
- [25:33] 它都能幫你代擾
- [25:34] 但它的原理呢
- [25:35] 我們在翻科學的這裡有深入的解說
- [25:38] 簡單來說就像是逐格放大後
- [25:41] 補上畫面上的細節的過程
- [25:43] 不過如果你要讓 Diffusion 產生影片
- [25:45] 那後果王是慘不忍睹
- [25:47] 就像威爾史密斯吃麵的影片
- [25:49] 每一格影格的連續性不見得相符
- [25:51] 看起來就超有惡趣味的
- [25:53] 不過要讓影格連續性看起來合理
- [25:56] 咦 那像是 GPT 自重 Transformer 模型
- [25:58] 不就是很擅長文字接龍找關聯性嗎
- [26:01] 要是讓 Transformer 模型來監督 Diffusion 做影片
- [26:03] 撒尿蝦加上牛丸
- [26:05] 一切不就迎刃而解了嗎
- [26:07] 沒錯 OpenEye 也是這樣想的
- [26:09] 因此才把 Sora 模型稱為 Diffusion Transformer
- [26:12] 還特別在官網上又寫題字標示起
- [26:14] 說是這樣說啦
- [26:15] 但 Transformer 就只會讀文本做文字接龍
- [26:18] 看不懂影片啊
- [26:19] 看不懂是要怎麼給建議
- [26:21] 於是一個能讓 Transformer 看懂影片跟圖片的方式
- [26:24] Patch 就誕生啦
- [26:26] CHA-GVT 理解內容的最小單位
- [26:28] 是 Token
- [26:29] Token 是類似單詞的文字語義
- [26:31] CHA-GVT 用 Token 玩文字接龍
- [26:33] 產生有連續且有意義的句子和文章
- [26:36] 那 Patch 呢
- [26:37] 其實就是圖片版的 Token
- [26:39] 讓 CHA-GVT 可以用圖片玩接龍
- [26:41] 玩出有連貫性的圖片
- [26:42] Sora 官方提供的訓練說明圖上
- [26:45] 最後形成的那些方塊就是 Patch
- [26:47] 這些 Patch 是包含時間在內的 4D 立體拼圖
- [26:51] 可以針對畫面與時間的連續性進行計算
- [26:54] 那這個 Patch 要怎麼做呢
- [26:56] 以 Sora 提供的參考文獻實物來說明會比較容易
- [26:59] Patch 是將影像切成一樣等大的區塊後
- [27:02] 進行編碼 壓縮
- [27:04] 產生類似 CHHA-GVT 能分析的文字語義 Token
- [27:07] 有了這些 Patch 後
- [27:09] Transformer 就可以計算 Patch 之間的關聯性
- [27:11] 形成序列
- [27:12] 例如論文中被分割在中上與右上的兩塊藍天
- [27:16] 就會被分類在天空中
- [27:18] 之後算圖時
- [27:19] 就會知道這兩塊 Patch 是一組的
- [27:21] 必須要一起算才行
- [27:22] 也就是說
- [27:23] 畫面上的這塊天空已經被鎖定了
- [27:26] 必須要一起動
- [27:27] 不然算不出來
- [27:28] 雖然這篇論文只提圖片
- [27:30] 但影片的處理只要再加上 Patch 間的先後順序
- [27:33] 這樣就能讓 Transformer 理解隨時間改變的演化
- [27:37] 同樣是上面被鎖定的天空
- [27:38] 多了先後順序
- [27:40] 就相當於是增加了前一個影格與後一個影格的限制條件
- [27:44] 讓這塊天空在畫面中移動時
- [27:46] 被限縮在一個特定範圍內
- [27:48] 運動軌跡就會看起來更合理
- [27:50] 這其實就很像是在做動畫的時候用的關鍵影格
- [27:54] 只要把關鍵影格 A 跟 B 設定完了
- [27:56] 中間交給程式跑
- [27:58] 就會跑出一個合理的東西出來
- [28:00] 而它的成果就是在 Sora 工廠上看到的驚人影片
- [28:03] 那種絲滑的高畫質
- [28:05] 具有空間與時間一致性的動作與印鏡
- [28:08] 甚至可以輕易的分割合成新的影片
- [28:11] 不過能把 Sora 模型訓練到這個程度
- [28:14] 依舊是符合 Open AI 大力出擊機的硬道理
- [28:17] 肯定是用了非常驚人的訓練量
- [28:20] 要是我是 Runway 或 Pika 這兩家小公司的人
- [28:23] 現在肯定是咬著牙流著血淚吧
- [28:26] 別哭
- [28:27] 我相信還是很多人想要看薇爾史碧斯
- [28:30] 繼續吃義大利麵的
- [28:31] Sora 的訓練過程是從提取影像特徵
- [28:34] 到形成有意義的 patch
- [28:36] 最後串連成序列
- [28:37] 如果你接觸過認知心理學
- [28:39] 你會發現
- [28:40] 這過程其實就跟認知心理學描述人類處理訊息的過程
- [28:44] 如出一側
- [28:45] 都是提取特徵
- [28:46] 幫特徵編碼形成意義
- [28:48] 最後組合成長期記憶形成序列
- [28:51] 可以說 Sora 已經接近複製人類的認知過程了
- [28:54] 這想想有點恐怖啊
- [28:56] 這邊是我的推測
- [28:57] 影片中那些逼真的物理效果
- [28:59] 不是有特定的物理模型或遊戲引擎在輔助
- [29:02] 而是在 patch 的訓練與序列的推理中
- [29:05] 就讓 Sora 理解到要讓物體這樣動
- [29:08] 看起來才會是真的
- [29:09] 這跟 GPT-4 不需要文法引擎是一樣的
- [29:12] 只要玩文字接龍
- [29:14] 就能生成流暢又有邏輯的文字跟代碼
- [29:17] 但這也是為什麼 GPT 很會胡說八道
- [29:21] 產生幻覺啦
- [29:22] 如果不是這樣
- [29:23] 我是很難想像 Sora 會算出這種影片
- [29:26] Sora 能理解視覺畫面
- [29:28] 並產生人類眼睛能接收的影片
- [29:30] 同樣的技術若能做出聽覺、觸覺等其他人類的感官
- [29:35] 那我們被 AI 圈養的時代是不是就越來越近了呢
- [29:39] 那麼後 Sora 時代到底會發生什麼事呢
- [29:42] 老實講 我不知道
- [29:43] 上面提到的 Diffusion Transformer 或 Patch
- [29:45] 都是近一年或是這幾個月才有研究成果的東西
- [29:49] 臉書母公司 Meta 的首席 AI 科學家 Young Lecon
- [29:53] 也在他自己的臉書公開抨擊
- [29:55] Sora 這種基於像素預測的技術
- [29:57] 註定會失敗
- [29:59] 是說今年初就有新聞在說
- [30:01] 祖克伯今年預計買超過 35 萬顆 H100 處理器
- [30:05] 這明顯就是要搞一波大的吧
- [30:06] 這就是我想要看到的血流成河
- [30:09] 而且從去年 Charge GPT 出來開始
- [30:12] 我感覺就已經不是在討論 AI 會怎麼發展
- [30:15] 而是要接受 AI 必定會發展的越來越快
- [30:18] 思考要怎麼面對 AI 帶來的機會與衝擊
- [30:21] 我們去年成立范科學院
- [30:23] 就是希望跟大家一起透過簡單易懂的教學影片
- [30:26] 把對 AI 的陌生與恐慌變成好奇與駕馭自如
- [30:30] Sora 或類似的模型應該可以協助我們把這件事情做得更好
- [30:34] 可惜的是 目前 OpenAI 僅開放 SORA
- [30:37] 給內部的 AI 安全團隊評估工具可能帶來的危害與風險
- [30:41] 另外就是有少數的藝術家、設計師以及電影製片人
- [30:45] 可以用來測試探索 SORA 在創意專業領域的實際應用
- [30:50] AI 軍備競賽打得活活熱熱
- [30:52] 各路大神除了各顯本領
- [30:54] 還聚眾嗆聲
- [30:55] 一方呼籲暫停訓練比 GPT-4 更強的模型
- [30:59] 另一方覺得這呼籲根本沒意義
- [31:01] 甚至有人覺得已經來不及了
- [31:03] 如果你也在擔心地球文明會被 AI 佔領
- [31:06] 或是世界變成由大企業掌控的賽博龐克反烏托邦
- [31:10] 我告訴你 早就是這樣了
- [31:12] 不是啦 我是要說 其實還有一線生機
- [31:15] 那就是我們的生物大腦
- [31:17] 這個濕軟的肉塊有機會再次打敗這些無機人工智慧
- [31:21] 不僅效能援甩他們好幾條街
- [31:24] 耗能也低上不少
- [31:25] 你相信嗎?
- [31:26] 2023年2月底
- [31:28] 約翰霍普金斯大學的教授 Thomas Harton 的研究團隊
- [31:32] 發表了類器官智慧 OI 的研究成果
- [31:35] 希望利用腦類器官加上腦機介面
- [31:39] 打造全新的生物計算技術
- [31:41] 我們終於要製造人工大腦了嗎?
- [31:44] OI 跟 AI 誰會成為未來的主宰?
- [31:48] OI 的全名是 Organoid Intelligence
- [31:54] 字面翻譯叫做類器官智慧
- [31:57] 這個全新的跨領域名詞
- [31:59] 同時結合了腦類器官跟腦機介面兩個領域的技術
- [32:04] 以前我們介紹過 Neuralink 外接的腦機介面
- [32:07] 但腦類器官又是什麼呢?
- [32:09] 簡單來說就是指科學家們透過培養或誘導多能幹細胞
- [32:14] 在模擬體內環境的旋轉生物反應器中產生的腦組織
- [32:19] 你沒聽錯
- [32:20] 人造腦組織的技術早就不只存在於科幻作品中了
- [32:24] 腦類器官技術其實不是新題材
- [32:27] 最早也不是為了開發類器官智慧 OI 才開始發展的
- [32:32] 早在2007年日本理研腦研究所的市井方數跟渡邊一一的研究團隊
- [32:38] 就成功從人類胚胎幹細胞培養前腦組織
- [32:42] 第一個具有不同腦區的3D腦類器官
- [32:46] 則是發表在2013年的Nature期刊上
- [32:48] 由奧地利分子技術研究所的尤爾根科布利西
- [32:52] 和馬德林蘭開斯特研究團隊成功建立
- [32:55] 腦類器官的出現在生物與醫學研究中有重大的意義
- [32:59] 這代表未來科學家們
- [33:01] 如果需要進行大腦相關的研究
- [33:03] 再也不用犧牲實驗動物或解剖大體老師
- [33:07] 來取得人類大腦
- [33:09] 只需要在培養皿裏製造出我們要的大腦就可以了
- [33:12] 但實際上真的那麼簡單嗎?
- [33:15] 培養皿上的組織確實是大腦組織
- [33:18] 但不論是在大小、功能以及解剖的構造上
- [33:21] 至今的結果仍遠遠不及我們自然發育形成的大腦
- [33:25] 因此要達到OI所需要的智慧水準
- [33:29] 我們必須擴大現有的腦類器官
- [33:31] 讓它成為一個更複雜更耐久的3D結構
- [33:35] 這個大腦也必須含有與學習有關的細胞和基因
- [33:39] 並讓這些細胞和AI以及機器學習系統相互連接
- [33:43] 透過這個新的模型、演算法以及腦機界面技術
- [33:47] 最終我們將能了解腦類器官是如何學習、計算、處理以及儲存
- [33:53] 講到這裡不免有人會擔心
- [33:56] 要是有一天OI真的產生智慧了
- [33:58] 我們是否就等於憑空創造出了某種生命呢?
- [34:02] 嗯?
- [34:03] 這勢必將引發不雜的道德倫理問題
- [34:06] 雖然研究團隊也強調
- [34:08] OI的目標並不是重新創造人類的意識
- [34:11] 而是研究與學習、認知和計算相關的功能
- [34:16] 但意識究竟是什麼?
- [34:17] 這種哲學思辨至今都還沒有結論
- [34:20] 到底懂得學習、計算的有機體能算是有意識嗎?
- [34:24] 如果將視覺腦機介面裝在OI上
- [34:27] 它是否會發現自己是受困於培養皿上
- [34:30] 被科學家們載割的生物計算機呢?
- [34:32] 但這些問題不僅是OI該擔心的問題
- [34:36] 隨著人工智慧的發展
- [34:37] GPT、BIN
- [34:39] 和其他由細構成的人造智慧
- [34:42] 他們通過了一個又一個的智力測試
- [34:45] 能力測試
- [34:46] 也終將面臨相應的哲學與倫理問題
- [34:49] 話說回來
- [34:50] 此刻就已經有不少人覺得
- [34:52] 有機大腦早被AI超越了
- [34:54] 類器官智慧OI能奔起直追
- [34:57] 甚至彎到超車嗎?
- [35:00] 首先我們先搞清楚一個問題
- [35:04] OI能不能算是AI的一種呢?
- [35:07] 這答案可以說是也不是
- [35:10] AI的A指的是Artificial
- [35:12] 所以原則上只要是人為製造的智慧
- [35:15] 我們都可以稱為AI
- [35:16] OI因為不是自然形成的
- [35:19] 是透過人為培養的生物神經細胞所產生的智慧
- [35:23] 所以聽起來OI也算是AI的一種啊
- [35:26] 但是許多人不這麼認為
- [35:28] 由於目前AI的開發都是透過數位電腦
- [35:31] 我們普遍將AI看作數位電腦產生的智慧
- [35:35] AI和OI的對比就好比是數位對上生物
- [35:39] 電腦對上人腦
- [35:41] 至於為何電腦運算的準確度和運算速度
- [35:44] 遠遠高於人腦
- [35:45] 最主要的原因是電腦的設計具有目的性
- [35:49] 生來就是要做快速且準確的線訊運算
- [35:52] 關於電腦的運作原理
- [35:54] 可以回去看我們介紹CPU與TPU的這一集
- [35:58] 反之呢
- [35:58] 大腦神經迴入不是設計用來處理線性問題
- [36:02] 而是處理複雜的模型
- [36:04] 神經元的連結是網狀的
- [36:06] 若拿這兩種不同運算結構的處理器做對比
- [36:10] 2022年登上世界最快運算寶座的超級電腦Frontier
- [36:14] 其實跟我們的人腦運算速度差不多
- [36:17] 但是要放下Frontier的主機
- [36:19] 需要680平方公尺面積的倉庫
- [36:23] 相比之下
- [36:23] 我們的大腦呢
- [36:24] 還不到一顆西瓜大
- [36:26] 這是因為大腦有將近860億個神經元
- [36:30] 但是交互的連結數量卻高達1000兆對
- [36:33] 並且神經迴入的連結是活的
- [36:36] 我們本身的基因組成
- [36:37] 以及每天接收的環境刺激
- [36:39] 不斷地改變著我們的大腦
- [36:41] 每一分每一秒
- [36:43] 我們的神經迴入都和之前的狀態不一樣
- [36:46] 所以即使拼單一的運算速度
- [36:48] 人腦比不上電腦
- [36:49] 但人腦卻有著更高的學習效率
- [36:52] 可延展性和能源使用效率
- [36:55] 在學習一個相同的新任務時
- [36:57] 電腦甚至需要消耗比人類多100億倍的能量才能完成
- [37:02] 看起來至少OI在硬體上的效率跟耗能上
- [37:06] 有著更高的優勢
- [37:07] 若能結合AI與OI的優點
- [37:10] 把AI的軟體搭載在OI的硬體上
- [37:13] 打造完美的運算系統
- [37:15] 似乎不是夢想
- [37:17] 但是OI的發展已經到達哪裡了呢?
- [37:19] 我們還距離這個目標有多遠呢?
- [37:25] 去年底澳洲腦科學公司
- [37:27] Cortical Labs的布雷特·卡根
- [37:30] 他帶領研究團隊培養出了
- [37:32] 會玩古早電子遊戲PONG的培養敏大腦
- [37:35] Dish Brand
- [37:36] 這個由80萬個細胞組成
- [37:38] 與雄風的腦神經元數量相近的Dish Brand
- [37:41] 雖然表現成績比不上AI
- [37:43] 但是對比於傳統的AI
- [37:45] 需要花超過90分鐘才能學會
- [37:48] 他只在短短5分鐘內就掌握了玩法
- [37:51] 能量消耗也比較少
- [37:53] 為了實現OI的目標
- [37:55] 培養更大的3D腦類器官是首要任務
- [37:59] 現階段約翰·霍普金斯、動物替代中心等機構
- [38:02] 其實只能生產出直徑大小約500微米
- [38:06] 也就是大約1粒鹽巴大小的尺寸
- [38:09] 這樣的腦類器官
- [38:10] 不過這樣的大小就已經含有
- [38:13] 約10萬個細胞的數目
- [38:15] 非常驚人
- [38:16] 雖然已經有其他的研究團隊
- [38:18] 透過超過一年的培養時間
- [38:20] 做出直徑3-5毫米的腦類器官
- [38:23] 但離目標的細胞數目
- [38:25] 1000萬的腦類器官還有一段距離
- [38:28] 此外腦類器官畢竟還是個生物組織
- [38:31] 卻不像生物大腦有著血管系統
- [38:34] 能夠進行氧氣、氧分、生長因子的灌流
- [38:37] 並移除代謝的廢物
- [38:39] 因此還需要有更完善的微流體灌流系統
- [38:42] 來支持腦類器官樣本的擴展性
- [38:45] 和長期穩定狀態
- [38:47] 在培養完成腦類器官
- [38:49] 以及確定能使其長期存活後
- [38:51] 最重要的任務就是進行
- [38:53] 腦器官訊息的輸入
- [38:55] 以及反應輸出的數據分析
- [38:58] 如此我們才能得知腦類器官如何進行生物計算
- [39:02] 受到腦波圖1EG記錄的啟發
- [39:05] 研究團隊將研發專屬腦類器官的3D微電極陣列
- [39:09] 如此能夠以類似頭戴腦波電極帽的方式
- [39:13] 把整個腦類器官用聚彈性且柔軟的外殼給包覆起來
- [39:18] 並用高解析度和高性造比的方式
- [39:21] 進行大規模的表面刺激與記錄
- [39:24] 如果想要更進一步透徹地分析腦類器官的訊號
- [39:28] 表面記錄是遠遠不夠的
- [39:31] 因此透過傷害最小化的侵入式記錄
- [39:34] 來獲取更高解析度的電生理訊號是非常重要的
- [39:38] 研究團隊將使用專門為活體實驗動物使用的
- [39:42] 細探針 Neuropixels
- [39:44] 進一步改良成類腦器官專用
- [39:47] 而且能夠靈活使用的裝置
- [39:50] 正所謂取長補短
- [39:52] 要成就OI
- [39:53] AI的使用跟貢獻一點也不可少
- [39:56] 下一步團隊將會進行腦機介面
- [39:59] 不過在這邊植入的腦
- [40:01] 將不再是人類或猴子的大腦
- [40:03] 而是腦類器官
- [40:05] 透過AI以及機器學習來找到腦類器官
- [40:08] 是如何形成學習記憶
- [40:10] 產生智慧
- [40:11] 過程中由於數據資料將會非常的龐大
- [40:14] 大數據的分析也是無可避免的
- [40:20] 2023年的現在
- [40:22] AI展現了驚人的實際成果
- [40:24] 從生成圖片的工具
- [40:26] 聊天機器人CheckGBT
- [40:28] 到現在百花齊放的AI工具
- [40:30] 相較之下
- [40:31] OI只是一個剛起步的計劃
- [40:34] 甚至連OI這個名稱
- [40:36] 其實也不是新的
- [40:37] 在2018年的時候
- [40:39] 美國自然物理學
- [40:40] 期刊專欄作家
- [40:42] 物理學家布凱南
- [40:43] 就以Organoise of Intelligence
- [40:45] 作為標題寫了一篇文章
- [40:47] 嚴格來說
- [40:48] 這還是一個舊技術的新包裝
- [40:51] 但隨著AI快速發展的趨勢
- [40:53] 和這次OI成果的發表
- [40:55] OI的網路聲量提升了不少
- [40:58] 或許將有機會獲得更多的關注
- [41:00] 與研究補助經費
- [41:01] 加速研究的進度
- [41:03] AI的發展怎麼看
- [41:04] 短時間內都不會趨緩
- [41:06] 而且還會持續加速
- [41:07] 飯團們好
- [41:08] 前陣子不知道各位是否有
- [41:10] Follow到一個很科幻的消息
- [41:12] 有一名Google工程師
- [41:13] 樂木英
- [41:14] 他上網公布了
- [41:15] 他自己跟他協助開發的
- [41:17] 對話型AI
- [41:19] Lambda之間的對話記錄
- [41:21] 宣稱這個AI
- [41:21] 已經具有知覺跟自我意識
- [41:24] 甚至能對悲慘世界
- [41:26] 有獨到的評論
- [41:28] 也略懂禪中
- [41:29] 甚至能冥想
- [41:30] 震驚的樂木英
- [41:32] 形容他就像一個七八歲的孩子
- [41:34] 而且Lambda還明確表達自己是人
- [41:37] 而非Google的財產
- [41:38] 難道說AI界最知名的圖靈測驗
- [41:41] 已經被Google功課了嗎
- [41:43] 提起圖靈
- [41:47] 大家心中應該會浮現
- [41:49] 以新世紀福爾摩斯
- [41:50] 奇異博士走紅
- [41:52] 人稱飾演天才專業戶的
- [41:54] 班乃迪克·康伯拜居的臉
- [41:56] 他曾在一部名為模仿遊戲的電影中
- [41:58] 詮釋了現代電腦科學概念之父
- [42:01] 艾倫·圖靈的傳奇一生
- [42:03] 他在二戰時期
- [42:04] 成功研發出一台
- [42:06] 能破解德軍密碼的計算器
- [42:08] BOM
- [42:09] 而後更完成了電腦數學的理論化
- [42:12] 在概念發展上
- [42:13] 仍是無人能出其誘
- [42:15] 例如他1936年提出的通用計算機
- [42:18] 圖靈機架構
- [42:19] 以及嘗試區隔AI
- [42:21] 與人的差異的哲學思考
- [42:23] 圖靈測驗
- [42:25] 圖靈測驗是一個思想實驗
- [42:27] 早在1950年
- [42:28] 第一台商用電腦
- [42:29] 連個影子都沒有的時代
- [42:31] 圖靈就已經思考到未來計算機的智慧表現
- [42:35] 將可能到達人類難辨真假的程度
- [42:38] 具體來說
- [42:39] 這個思想實驗是如果一台機器能夠透過介面
- [42:43] 與不知道對面是機器人或是人類的受試者展開對話
- [42:47] 而不被辨認出他的機械身份
- [42:49] 那麼就可以稱這台機器具有智慧
- [42:52] 但我們也知道智慧有很多面向跟層次
- [42:56] 語言跟問題回應都不一定能反映這台機器有沒有智慧
- [43:00] 因此這個思想實驗的有效性
- [43:02] 也被許多科學家和心理學家質疑
- [43:05] 即使如此簡單粗暴的模仿遊戲
- [43:08] 至今其實也沒人能攻克
- [43:10] 欸等等
- [43:11] 你可能會想到影片開場提到的Google工程師勒姆英
- [43:15] 他不是已經分不出來對面是機器還是人了嗎
- [43:18] 原因很簡單
- [43:19] 他自己就是AI的開發者
- [43:21] 而不是圖靈測試設定中的不知情受試者
- [43:24] 因此根本不能算數
- [43:26] 除非Google拿這個AI給不知情的民眾做測試
- [43:29] 欸 8 月 28 號
- [43:31] Google 已經將這個對話機器人
- [43:34] 以 AI Test Kitchen 項目
- [43:36] 開放部分美國人做小規模測試
- [43:39] 其中包含了 Imagine it 想像一下
- [43:42] 只要你說出一個想像或實際存在的地點
- [43:45] Lambda 就會嘗試以文字描述
- [43:47] 而另一個 Listen 列個清單
- [43:50] 則會幫你摘要分類起你提供的清單內容
- [43:53] 最後最有可能跟圖靈測驗有關係的 Talk about it
- [43:57] 你說看看項目呢
- [43:59] 則可以針對特定主題
- [44:01] 與使用者進行自由對談
- [44:03] 搞不好等到這個封閉測試結束後
- [44:05] 我們會真的分不清楚
- [44:07] 現在到底是人還是 AI 在跟我們對話
- [44:10] 屆時也許就真能達成
- [44:12] 通過圖靈測試這個 AI 里程碑
- [44:19] 這已經不是 Google 第一次用 AI 震驚世人了
- [44:22] 那我們回到 2016 年的圍棋大賽會場
- [44:25] 當時 Google 搜購的公司
- [44:26] Demmai 研發的圍棋計算 AI
- [44:29] Alpha Go
- [44:29] 以四勝一敗
- [44:31] 擊敗了韓國騎王李世時
- [44:33] 而後又於 2017 年
- [44:34] 三戰全勝當時世界騎王柯傑
- [44:37] 若這場對意發生在網路上
- [44:40] 這就像是麒麟王中
- [44:41] 左圍以賽為畫名
- [44:43] 擊敗塔屎名人
- [44:45] 我們是否真的能夠分辨
- [44:47] 在電腦對面跟你下棋的
- [44:48] 是 AI 藤原左圍還是黑++ 呢
- [44:52] 而這樣玄妙的畫面
- [44:54] 當年還真的發生了
- [44:55] 就在 2016 年末
- [44:57] 網路奇壇上一個名為 Master 的帳號出現
- [45:00] 專挑職業騎手對意
- [45:02] 最後獲得 60 勝一盒
- [45:04] 這麼大殺四方的成績
- [45:06] 而在第 54 局
- [45:07] 和中國騎盛聶未平對意後
- [45:10] Master 首次打出繁體中文
- [45:12] 謝謝聶老師
- [45:13] 在第 60 局對上中國的鼓勵九段
- [45:16] Master 更自曝身份
- [45:18] 說出自己就是 AlphaGo 的黃博士
- [45:21] 這位黃博士
- [45:22] 就是打從 2012 就開發出
- [45:24] 國產圍棋城市 Erika
- [45:26] 而後被 Dimmai 公司挖角
- [45:28] 參與開發 AlphaGo 的
- [45:29] 台灣資深工程師黃世傑
- [45:32] 不論是讓工程師自己都認知錯案的 Lambda
- [45:35] 或是在圍棋界痛載各路其亡的 AlphaGo
- [45:39] 驚嘆之餘
- [45:40] 我們更好奇的是
- [45:41] 他們是怎麼開發出來的
- [45:43] 讓我們來看看歷代電腦科學家們
- [45:49] 他們是如何發展出各種人工智慧
- [45:51] 一路迎來現在幾乎
- [45:53] 琴棋詩書樣樣金的黃金時代
- [45:56] 我先提醒大家
- [45:57] 這過程可不是一帆風順
- [45:59] 這就像股票一樣起起落落
- [46:01] 在 AI 的發展史上
- [46:03] 套勞過無數的科學家
- [46:05] 人工智慧這概念是在 1956 年提出
- [46:08] 麥卡錫、明斯基、羅切斯特跟香農
- [46:11] 這幾位 AI 鼻祖
- [46:12] 還有其他的幾位研究者
- [46:14] 共同參與了一個名為
- [46:16] 達特茅斯夏季人工智慧研究會的會議
- [46:19] 這一年也被公認為 AI 元年
- [46:22] 在會議中
- [46:23] 除了人工智慧這個詞以外
- [46:25] 當年這些金頭腦們
- [46:27] 就已經提出大家現在很熟悉的
- [46:29] 自然語言處理
- [46:30] 像是 Siri 之類的
- [46:32] 還有神經網路等等概念
- [46:34] 而這個會議當下
- [46:35] 正好遇上美蘇冷戰跟科技競賽的時代
- [46:38] 所以美蘇兩大陣營
- [46:40] 除了在大家耳熟能詳的
- [46:42] 阿波羅系列等太空任務上較勁
- [46:45] 他們其實也投資了大量資源在電腦科學上
- [46:48] 期待能夠像圖林當年那樣
- [46:50] 開發出扭轉戰局的電腦科技
- [46:53] 而他們也不負所託
- [46:54] 產出了很多有趣的應用
- [46:56] 例如第一個具備學習能力的跳棋程式
- [46:59] 或是聊天機器人Eliza
- [47:02] 又或者是醫療診斷系統
- [47:04] Mysyn
- [47:05] 史丹佛大學甚至從那時候開始
- [47:07] 研發現在很夯的汽車自動駕駛技術
- [47:10] 然而到了70年代初期
- [47:12] AI 的發展遭遇許多瓶頸
- [47:14] 主要是研究者們慢慢發現
- [47:16] 即使他們開發的AI
- [47:18] 已經擁有簡單的邏輯跟推理能力
- [47:20] 甚至一定程度的學習能力
- [47:22] 但人離所謂的智慧跟判斷能力差得太遠
- [47:26] 使得當時的AI
- [47:28] 甚至被批評為只能解決所謂的玩具問題
- [47:31] 也因為能解決的問題太有限
- [47:34] 導致出資的英美政府失去了信心
- [47:37] AI 研究領域迎來了第一次寒冬
- [47:39] Winter is here
- [47:41] 而這並非當時的科學家能力不足
- [47:44] 而是他們生錯了時代
- [47:46] 例如我們現在都經常聽到的類神經網路
- [47:49] 就是前述的AI鼻祖明斯基提出的
- [47:52] 欸 這就像仿生獸的創造者一樣
- [47:54] 他也想從大自然中找答案
- [47:56] 而既然要探索智慧
- [47:58] 明斯基有直接模仿人類腦細胞
- [48:00] 做出第一台神經網路學習機
- [48:03] 但當年受限於電腦硬體效能
- [48:06] 跟可用的資料不足
- [48:07] 使類神經網路沒有辦法像現在一樣陽明立萬
- [48:11] 在寒冬之中
- [48:12] 另一位大神麥卡錫認為
- [48:14] 追求智慧跟思考是原木求魚
- [48:17] 不如利用機器比我們還強大的優勢邏輯跟運算能力
- [48:21] 來幫我們解決問題就好了
- [48:23] 因此演進出了專家系統這條路線
- [48:26] 帶來人工智慧的復興
- [48:28] 專家系統的本質就是把所有參數跟結果塞進去
- [48:33] 用搜索跟運算的方式來回答問題
- [48:36] 這種人工智慧特別適合解決一些
- [48:39] 有明確答案的專業問題
- [48:41] 所以被稱為專家系統
- [48:43] 例如醫生針對已知的病徵
- [48:45] 開立處方用藥或是法律相關問題
- [48:48] 隨著電腦運算效能的大提升
- [48:51] 專家系統在復興之路上有不少發揮跟成果
- [48:55] 但很快又遇到下一個瓶頸
- [48:57] 就是專家系統無法面對新問題
- [49:04] 例如即使能夠將開處方簽這件事情自動化
- [49:07] 卻沒有辦法對應新的疾病
- [49:09] 例如COVID-19
- [49:11] 或是還沒來得及輸入資料庫的新型藥品
- [49:14] 這離取代醫生太遠了
- [49:16] 於是就像景氣循環一樣
- [49:18] 大量投資的熱錢又開始泡沫化
- [49:21] 人工智慧迎來了第二次寒冬
- [49:24] 許多電腦科學家甚至改自稱自己
- [49:27] 在做自動化設計或最佳化系統等等
- [49:30] 來掩人耳目
- [49:31] 避免被暢衰
- [49:32] 而明斯基沒有放棄
- [49:34] 仍然堅持有可能讓機器像人類般思考
- [49:38] 他所提出的神經網路就是參考神經科學家的發現
- [49:42] 人類的神經元是透過網狀傳遞電訊號來產生意識跟智慧
- [49:47] 因此他就從這個面向切入提出了類神經網路的概念
- [49:51] 透過多層次與無數參數形成網狀影響的運算方式
- [49:55] 形成類似人腦的複雜決策系統
- [49:58] 而運算的答案不再是專家系統那樣非黑即白
- [50:02] 甚至只要改變成數或是各參數的權重
- [50:05] 答案就會有所不同
- [50:06] 因此如何調教出可用的類神經網路
- [50:09] 就成了這學門最核心的研究方向
- [50:12] 這概念非常合理
- [50:14] 可惜受限於當時電腦硬體能力跟資料量
- [50:17] 因此原型機能解決問題的速度
- [50:20] 還不如傳統統計方式
- [50:22] 但隨著電晶體的高速發展
- [50:24] 以及網路世代帶來的海量資料
- [50:26] 類神經網路這門技藝
- [50:28] 開始文藝復興
- [50:30] 1984年
- [50:31] 美國普林斯頓大學的物理學家
- [50:33] 跟神經學家霍普菲爾德
- [50:35] 用模擬集成電路完成了新的類神經網路模型
- [50:39] 而雲端運算
- [50:40] 大量資料讓科學家可以輕易的餵養資料訓練模型
- [50:44] 更能夠增加更多隱含層
- [50:46] 讓運算更複雜
- [50:47] 這種深度學習技術
- [50:49] 讓人工智慧的第二次寒冬
- [50:51] 看見暖陽
- [50:52] 從李飛飛推出的ImageNet年度競賽開始
- [50:55] 演化到Google的AlphaGo
- [50:57] AI開始能夠認得圖像上的物件
- [51:00] 甚至攻克本來認為不可能攻克的圍棋領域
- [51:04] 為何會說圍棋曾經被認為不可能攻克呢?
- [51:07] 因為每一盤圍棋的複雜度
- [51:09] 可是高達10的172次方
- [51:12] 比現在已知的宇宙原子數量還多
- [51:15] 因此圍棋界才有千古無銅局的說法
- [51:18] 相較起來1977年IBM的深藍攻克的西洋棋
- [51:22] 複雜度只有10的46次方
- [51:25] 但也動用了30台電腦
- [51:27] 加裝480加速運算晶片
- [51:29] 基本上就有如火鳳燎原中
- [51:31] 八旗思維的
- [51:32] 我知道你的下一步的下一步
- [51:35] 當年深藍每一次下棋
- [51:37] 可是都暴力計算到了後面12步的發展
- [51:40] 才打敗西洋棋世界冠軍
- [51:42] 卡斯帕羅夫
- [51:43] 這個AlphaGo到底是怎麼算出這麼複雜的圍棋呢?
- [51:47] 難道它能像是奇異博士一樣
- [51:49] 利用時間寶石
- [51:51] 演算出1400多萬種平行宇宙的可能性才弱子嗎?
- [51:55] 這就要提到Deep My公司非常有趣的洞見了
- [51:58] 那就是真正的智慧
- [52:00] 是捨棄那些無需多想
- [52:02] 壓根不可能成功的可能性
- [52:04] Google 工程師使用了一種叫做蒙蒂卡羅素搜尋的方式
- [52:08] 一方面讓AlphaGo大量隨機生成類神經網路參數跟層數
- [52:13] 二方面讓它快速搜尋
- [52:15] 並略過不需要運算的路徑
- [52:18] 這其實是我們日常生活中很熟悉的現象
- [52:21] 人腦的諧思
- [52:22] 也就是直接專注於我們要解決的問題
- [52:25] 忽略周遭的雜訊或多餘的想法
- [52:29] 而類神經網路的設計思維是尋求最佳解
- [52:32] 而非唯一解
- [52:33] 即使AlphaGo也會下錯棋
- [52:35] 也曾輸給理事實
- [52:37] 但關鍵是能夠在有限的資訊跟時間中得到答案
- [52:41] 除了下出神之一手之外
- [52:43] AlphaGo這樣的AI能做的事情還多著了
- [52:46] Dipmai用AlphaGo打遍天下無敵手之後
- [52:49] 宣布讓AlphaGo退休
- [52:51] 而後續他們將這套技術拿去學玩攤石蛇
- [52:54] 打星海爭霸
- [52:56] 展現出超越電競選手的技巧
- [52:58] 現在甚至能預測蛋白質結構
- [53:00] 或比醫生更精準地判定乳癌
- [53:03] 最後我們回到一開始的問題
- [53:09] 實用化的Lambda究竟有沒有可能通過土靈測試呢?
- [53:13] 目前Google仍然強烈否認Lambda具有知覺
- [53:16] 而樂木英也因為涉嫌洩漏商業機密而被停職
- [53:20] 英國謝菲爾德大學機器人學院教授羅傑摩爾
- [53:24] 他澄清這個AI背後的算法體系
- [53:26] 只是
- [53:27] 磁序建模
- [53:28] 而不是
- [53:29] 語言建模
- [53:30] 他強調對答如流的Lambda
- [53:32] 會給你太有人格的感覺
- [53:34] 只是錯覺
- [53:35] 不過在Lambda最新的應用中
- [53:38] Google找來了13個作家
- [53:39] 測試以Lambda為基礎開發的協作協助工具
- [53:43] Lambda Worldcraft
- [53:45] 運作方式有點像手機輸入法的關聯字詞推薦概念
- [53:49] 但他的設計完全是為了文字創作者而生
- [53:52] 利用整個網際網路的文字
- [53:54] 他彷彿擁有了類似龍格的集體潛意識能力
- [53:58] 當小說家起了一個頭
- [54:00] 他就能夠開始推薦下一個單詞
- [54:02] 甚至一整個句子來補完
- [54:04] 甚至還能夠調整深層文字的風格
- [54:07] 例如有趣或是憂鬱
- [54:09] 這些應用聽起來簡直像是科幻小說
- [54:12] 妙的是
- [54:13] 參與測試的作家之一
- [54:15] 正式成翻譯三體英文版
- [54:17] 並寫出摺紙動物園的科幻小說家劉宇坤
- [54:20] 他形容這個工具讓他數次突破創作的瓶頸
- [54:24] 節約了自己的腦容量
- [54:25] 專注於創作故事最重要的東西
- [54:28] 更驚人的是
- [54:29] 他提到有一次他連開頭的靈感都沒有
- [54:32] 因此他把創作的主動權交給了Lambda
- [54:36] 並從中看到了從未想過的可能性
- [54:39] 有了繼續寫下去的新寫作靈感
- [54:41] 眼藍就像當年AlphaGo下出一些人類棋谱中從沒想過的棋路一樣
- [54:47] 有了洞見
- [54:48] 到了這個地步
- [54:49] 你仍然堅持AI只是我們拿來解決問題的工具
- [54:52] 而不具備一定程度的對人文的認知或智慧嗎
- [54:57] 最後想問問大家
- [54:58] 劉宇坤他使用Lambda Warcraft創造出的短篇小說
- [55:02] 你認為這個作品的著作權應該屬於誰呢?
- [55:05] 是劉宇坤本人嗎?
- [55:07] 還是Lambda Warcraft應該跟劉宇坤並列為共同作者呢?
- [55:12] 又或是古往近來所有的文字創作者呢?
- [55:15] 又或者你認為根本沒有人
- [55:18] 因為使用Lambda Warcraft的創作應該要被列為人類公共財呢?
- [55:22] 好的以上就是本集的內容
- [55:24] 如果你對人工智慧的科學有更多的好奇
- [55:27] 歡迎加入范科會員來提案
- [55:29] 記得訂閱開啟小鈴鐺
- [55:30] 分享我們的影片
- [55:32] 我們下次再見囉
